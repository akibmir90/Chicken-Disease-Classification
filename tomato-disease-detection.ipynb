{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Tomato Disease Detection Project\n\nWelcome to my Tomato Disease Detection project! In this notebook, I'll walk you through the process and results of my project, where I developed a machine learning model to detect and classify diseases in tomato plants.\n\n## Project Background\n\nTomato farming is essential for global food production, but it faces significant challenges due to various diseases that can affect tomato plants. Early detection and accurate classification of these diseases are crucial for crop management and ensuring food security.\n\n## Dataset\n\nI used a comprehensive dataset of tomato plant images, including examples of healthy plants and various disease states. This dataset serves as the foundation for training and evaluating my machine learning model.\n\n## Project Goals\n\nThe primary objectives of this project are as follows:\n- Build and train a machine learning model to accurately detect diseases in tomato plants.\n- Classify the specific disease type if present.\n- Evaluate the model's performance using appropriate metrics.\n\n## Methodology\n\nI will employ deep learning techniques, specifically convolutional neural networks (CNNs), for image classification. I'll also explore data preprocessing, model architecture, and fine-tuning to achieve the best possible results.\n\n## Project Structure\n\nThis notebook is organized as follows:\n1. Data Preparation: Exploring and preprocessing the dataset.\n2. Model Development: Building and training the CNN model.\n3. Model Evaluation: Assessing the model's performance and discussing the results.\n4. Conclusion: Summarizing the findings and potential future work.\n\nLet's get started with the project and dive into the fascinating world of tomato disease detection!\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-08-20T13:05:37.189036Z","iopub.execute_input":"2023-08-20T13:05:37.189423Z","iopub.status.idle":"2023-08-20T13:05:47.093951Z","shell.execute_reply.started":"2023-08-20T13:05:37.189372Z","shell.execute_reply":"2023-08-20T13:05:47.092894Z"}}},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\nfrom tensorflow.keras.optimizers import RMSprop\nimport matplotlib.pyplot as plt","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Setting Paths for Training and Validation Data\n\nIn this project, we'll be working with a dataset of tomato leaf images to train and validate our machine learning model for tomato disease detection. To do this, we need to specify the paths to the folders containing our training and validation datasets.\n\nThe training data typically includes a large set of images used to train our model, while the validation data is used to assess the model's performance on unseen data.\n\nLet's define the paths to our training and validation data folders:\n\n- `train_path`: This path points to the directory containing our training data. These images will be used to train our model to recognize various tomato diseases.\n\n- `valid_path`: This path leads to the folder with our validation data. The validation dataset is crucial for evaluating how well our trained model generalizes to new, unseen tomato leaf images.\n\nNow that we've set the paths to our data, we can proceed to load and preprocess the images, build our model, and begin training it to detect tomato diseases.\n","metadata":{}},{"cell_type":"code","source":"# Set paths to train and validation folders\ntrain_path = \"/kaggle/input/tomatoleaf/tomato/train\"\nvalid_path = \"/kaggle/input/tomatoleaf/tomato/val\"","metadata":{"execution":{"iopub.status.busy":"2023-08-20T13:05:20.603021Z","iopub.execute_input":"2023-08-20T13:05:20.603677Z","iopub.status.idle":"2023-08-20T13:05:20.609056Z","shell.execute_reply.started":"2023-08-20T13:05:20.603644Z","shell.execute_reply":"2023-08-20T13:05:20.608110Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Preprocessing with ImageDataGenerator\n\nTo effectively train a deep learning model for tomato disease detection, it's crucial to prepare and preprocess the dataset appropriately. In this section, we'll discuss the data preprocessing steps using the `ImageDataGenerator` from Keras.\n\nThe following code sets up our data preprocessing pipeline:\n\n- `image_size`: We define the desired image size for our dataset. In this case, we've set it to (224, 224) pixels, a common choice for many deep learning models.\n\n- `batch_size`: This parameter determines the number of images processed in each training iteration. A batch size of 32 means that the model will update its weights after processing 32 images.\n\n- `train_datagen`: Here, we configure an `ImageDataGenerator` for augmenting and preprocessing the training images. These transformations help enhance the model's ability to generalize from the limited training data. The specific operations include:\n    - `rescale=1.0/255`: Scaling pixel values to the range [0, 1] to ensure consistent input to the model.\n    - `rotation_range=20`: Randomly rotating images by up to 20 degrees to introduce variety.\n    - `width_shift_range=0.2` and `height_shift_range=0.2`: Shifting the image horizontally and vertically by up to 20% of the image width or height, respectively.\n    - `shear_range=0.2`: Applying shear transformations to the images.\n    - `zoom_range=0.2`: Zooming in or out on images by up to 20%.\n    - `horizontal_flip=True`: Flipping images horizontally, which increases data diversity.\n\nThese preprocessing steps, such as rotation, shifting, and flipping, will help our model become more robust and better at detecting tomato diseases in various conditions. With the data preprocessing pipeline in place, we're ready to load the dataset, create data generators, and start training our model.\n","metadata":{}},{"cell_type":"code","source":"# Define image data generators with data augmentation\nimage_size = (224, 224)\nbatch_size = 32\ntrain_datagen = ImageDataGenerator(\n    rescale=1.0/255,\n    rotation_range=20,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True\n)","metadata":{"execution":{"iopub.status.busy":"2023-08-20T13:05:51.553012Z","iopub.execute_input":"2023-08-20T13:05:51.553737Z","iopub.status.idle":"2023-08-20T13:05:51.559895Z","shell.execute_reply.started":"2023-08-20T13:05:51.553700Z","shell.execute_reply":"2023-08-20T13:05:51.558715Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"valid_datagen = ImageDataGenerator(rescale=1.0/255)","metadata":{"execution":{"iopub.status.busy":"2023-08-20T13:05:51.922962Z","iopub.execute_input":"2023-08-20T13:05:51.923317Z","iopub.status.idle":"2023-08-20T13:05:51.928893Z","shell.execute_reply.started":"2023-08-20T13:05:51.923284Z","shell.execute_reply":"2023-08-20T13:05:51.927656Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Creating Data Generators for Training and Validation\n\nNow that we've defined our data preprocessing pipeline using `ImageDataGenerator`, the next step is to create data generators for both our training and validation datasets. These data generators will efficiently load and augment the data, making it ready for training our tomato disease detection model.\n\nHere's how we set up the data generators:\n\n- `train_generator`: We create a data generator for our training dataset using the `flow_from_directory` method. This generator will load images from the `train_path`, which we defined earlier, and perform the following actions:\n    - `directory`: Specifies the directory where the training images are located.\n    - `target_size`: Sets the desired image size, which we previously defined as (224, 224) pixels.\n    - `batch_size`: Determines the number of images processed in each training iteration, and we've set it to 32.\n    - `class_mode`: We specify \"categorical\" as the class mode, indicating that our model will predict categories (disease classes) using one-hot encoding.\n\n- `valid_generator`: Similarly, we create a data generator for our validation dataset using the same `flow_from_directory` method. This generator loads images from the `valid_path` and applies the same settings as the training generator.\n\nThese data generators are crucial for training and evaluating our model efficiently. They handle the loading of images, apply the data augmentation transformations defined earlier, and organize the data into batches. This setup allows us to feed the data seamlessly to our model during the training process.\n\nWith the data generators in place, we're one step closer to building and training our tomato disease detection model effectively.\n","metadata":{}},{"cell_type":"code","source":"train_generator = train_datagen.flow_from_directory(\n    directory=train_path,\n    target_size=image_size,\n    batch_size=batch_size,\n    class_mode=\"categorical\"\n)","metadata":{"execution":{"iopub.status.busy":"2023-08-20T13:05:52.353902Z","iopub.execute_input":"2023-08-20T13:05:52.355082Z","iopub.status.idle":"2023-08-20T13:06:03.027327Z","shell.execute_reply.started":"2023-08-20T13:05:52.355032Z","shell.execute_reply":"2023-08-20T13:06:03.026412Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"valid_generator = valid_datagen.flow_from_directory(\n    directory=valid_path,\n    target_size=image_size,\n    batch_size=batch_size,\n    class_mode=\"categorical\"\n)","metadata":{"execution":{"iopub.status.busy":"2023-08-20T13:06:03.029211Z","iopub.execute_input":"2023-08-20T13:06:03.029557Z","iopub.status.idle":"2023-08-20T13:06:03.281115Z","shell.execute_reply.started":"2023-08-20T13:06:03.029528Z","shell.execute_reply":"2023-08-20T13:06:03.280211Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Displaying Random Images from Dataset Subfolders\n\nIn the process of working with image datasets, it's essential to get a visual sense of the data. This code snippet provides a utility function, `display_random_images`, that allows us to display a random selection of images from subfolders within a specified directory. This can be particularly useful for exploring the diversity and content of our tomato disease dataset.\n\n\n- `display_random_images(directory, num_images=9, num_columns=3)`: This is the main function. It takes three parameters:\n    - `directory`: The directory where the dataset subfolders are located.\n    - `num_images` (optional, default=9): The number of random images to display.\n    - `num_columns` (optional, default=3): The number of columns in the display grid.\n\nThe function performs the following steps:\n1. It identifies subfolders within the specified directory.\n2. Randomly selects one of these subfolders.\n3. Lists the image files within the chosen subfolder.\n4. Randomly selects `num_images` from the available images.\n5. Creates a grid for displaying the selected images, arranging them in rows and columns.\n6. Displays the images with their filenames as titles.\n\nThis utility function can help you visually inspect your dataset, ensuring that it contains a diverse set of images representing different classes or categories. It's also a handy tool for data exploration and quality control.\n\nTo use this function in your notebook, simply call `display_random_images` with the appropriate directory containing your tomato disease images and the desired number of images to display.\n","metadata":{}},{"cell_type":"code","source":"import os\nimport random\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n\ndef display_random_images(directory, num_images=9, num_columns=3):\n    subfolders = [subfolder for subfolder in os.listdir(directory) if os.path.isdir(os.path.join(directory, subfolder))]\n    if len(subfolders) == 0:\n        print(f\"No subfolders found in {directory}\")\n        return\n    \n    random_subfolder = random.choice(subfolders)\n    subfolder_path = os.path.join(directory, random_subfolder)\n    image_files = [filename for filename in os.listdir(subfolder_path) if filename.lower().endswith(('.png', '.jpg', '.jpeg'))]\n    if len(image_files) < num_images:\n        print(f\"Number of available images in {subfolder_path} is less than {num_images}\")\n        return\n    \n    random_files = random.sample(image_files, num_images)\n    num_rows = (num_images + num_columns - 1) // num_columns\n    plt.figure(figsize=(15, 10))\n    \n    for i, filename in enumerate(random_files):\n        img_path = os.path.join(subfolder_path, filename)\n        img = mpimg.imread(img_path)\n        plt.subplot(num_rows, num_columns, i + 1)\n        plt.imshow(img)\n        plt.axis('off')\n        plt.title(filename)\n    \n    plt.tight_layout()\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-08-20T13:06:03.282886Z","iopub.execute_input":"2023-08-20T13:06:03.283595Z","iopub.status.idle":"2023-08-20T13:06:03.295044Z","shell.execute_reply.started":"2023-08-20T13:06:03.283557Z","shell.execute_reply":"2023-08-20T13:06:03.294128Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Call the function with the desired directory and number of images\ndisplay_random_images(train_path, num_images=9, num_columns=3)\n","metadata":{"execution":{"iopub.status.busy":"2023-08-20T13:06:03.297830Z","iopub.execute_input":"2023-08-20T13:06:03.298622Z","iopub.status.idle":"2023-08-20T13:06:05.528264Z","shell.execute_reply.started":"2023-08-20T13:06:03.298586Z","shell.execute_reply":"2023-08-20T13:06:05.527028Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Call the function with the desired directory and number of images\ndisplay_random_images(valid_path, num_images=9, num_columns=3)","metadata":{"execution":{"iopub.status.busy":"2023-08-20T13:06:05.529606Z","iopub.execute_input":"2023-08-20T13:06:05.530144Z","iopub.status.idle":"2023-08-20T13:06:06.988730Z","shell.execute_reply.started":"2023-08-20T13:06:05.530077Z","shell.execute_reply":"2023-08-20T13:06:06.987444Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Creating a Convolutional Neural Network (CNN) Model\n\nIn the heart of our tomato disease detection project lies the neural network model responsible for classifying tomato leaf images. Convolutional Neural Networks (CNNs) are a powerful choice for image classification tasks, and here, we define our CNN model using the Keras library.\n\nHere's a breakdown of the code:\n\n- `num_classes`: We calculate the number of classes (disease categories) based on the number of classes defined in our training data using `train_generator.class_indices`. This value is essential for configuring the output layer of the model.\n\n- `model = Sequential([...])`: We create a sequential model, a linear stack of layers, and define its architecture. Our model consists of the following layers:\n\n    - `Conv2D(32, (3, 3), activation=\"relu\", input_shape=(224, 224, 3))`: The first convolutional layer with 32 filters of size (3, 3), ReLU activation, and input shape (224, 224, 3). This layer extracts features from input images.\n    \n    - `MaxPooling2D(2, 2)`: Max-pooling layer with a 2x2 pooling window. It reduces spatial dimensions and retains important features.\n    \n    - `Conv2D(64, (3, 3), activation=\"relu\")`: A second convolutional layer with 64 filters and ReLU activation.\n    \n    - `MaxPooling2D(2, 2)`: Another max-pooling layer to further reduce spatial dimensions.\n    \n    - `Flatten()`: This layer flattens the output from the previous layers into a one-dimensional vector.\n    \n    - `Dense(128, activation=\"relu\")`: A fully connected (dense) layer with 128 neurons and ReLU activation.\n    \n    - `Dropout(0.5)`: Dropout layer with a dropout rate of 50%. Dropout helps prevent overfitting by randomly deactivating neurons during training.\n    \n    - `Dense(num_classes, activation=\"softmax\")`: The final dense layer with `num_classes` neurons (equal to the number of disease categories) and softmax activation. This layer produces class probabilities for each category.\n\nThis architecture represents a common design for CNNs in image classification tasks. However, you can experiment with different architectures, hyperparameters, and regularization techniques to fine-tune the model's performance for your specific dataset.\n\nWith the CNN model defined, we're ready to compile it, train it on our dataset, and evaluate its performance in later sections of the notebook.\n","metadata":{}},{"cell_type":"code","source":"# Create a CNN model\nnum_classes = len(train_generator.class_indices)\nmodel = Sequential([\n    Conv2D(32, (3, 3), activation=\"relu\", input_shape=(224, 224, 3)),\n    MaxPooling2D(2, 2),\n    Conv2D(64, (3, 3), activation=\"relu\"),\n    MaxPooling2D(2, 2),\n    Flatten(),\n    Dense(128, activation=\"relu\"),\n    Dropout(0.5),\n    Dense(num_classes, activation=\"softmax\")\n])","metadata":{"execution":{"iopub.status.busy":"2023-08-20T13:06:06.990295Z","iopub.execute_input":"2023-08-20T13:06:06.990985Z","iopub.status.idle":"2023-08-20T13:06:11.633092Z","shell.execute_reply.started":"2023-08-20T13:06:06.990946Z","shell.execute_reply":"2023-08-20T13:06:11.632141Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Compiling and Training the CNN Model\n\nWith our CNN model architecture defined, it's time to compile and train the model to learn from our tomato disease dataset. In this section, we'll cover the necessary steps for model compilation and training.\n\n- `from tensorflow.keras.optimizers import Adam`: We import the Adam optimizer from the TensorFlow library. The optimizer is responsible for updating the model's weights during training to minimize the loss function.\n\n- `model.compile(...)`: We compile the model by specifying its configuration. Here's what each argument does:\n    - `optimizer=Adam(lr=0.0001)`: We choose the Adam optimizer as our optimizer with a learning rate of 0.0001. You can adjust the learning rate based on your experimentation and the specific dataset.\n    - `loss=\"categorical_crossentropy\"`: We use categorical cross-entropy as the loss function since this is a multi-class classification problem.\n    - `metrics=[\"accuracy\"]`: We specify that we want to track the accuracy metric during training.\n\n- `from tensorflow.keras.callbacks import EarlyStopping`: We import the EarlyStopping callback from TensorFlow. This callback allows us to monitor the model's validation accuracy and stop training early if it stops improving.\n\n- `early_stopping = EarlyStopping(...)`: We define the EarlyStopping callback with the following arguments:\n    - `monitor='val_accuracy'`: We monitor the validation accuracy.\n    - `patience=5`: Training will stop if there is no improvement in validation accuracy for 5 consecutive epochs.\n    - `restore_best_weights=True`: After early stopping, the model's weights will be restored to the best weights obtained during training.\n\n- `model.fit(...)`: We train the model using the `fit` method. The arguments are as follows:\n    - `train_generator` and `valid_generator`: These are the data generators we created earlier for the training and validation datasets.\n    - `steps_per_epoch` and `validation_steps`: These parameters are set to the number of batches in the training and validation generators, respectively.\n    - `epochs=50`: We specify the maximum number of training epochs. The training may stop earlier if the EarlyStopping criteria are met.\n    - `callbacks=[early_stopping]`: We include the EarlyStopping callback to monitor and control training.\n\nWith this setup, our CNN model will be trained on the tomato disease dataset, and the training will stop early if validation accuracy does not improve for a defined number of epochs. This helps prevent overfitting and ensures that we have the best-performing model.\n","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.optimizers import Adam\n\n# Compile the model with Adam optimizer\nmodel.compile(\n    optimizer=Adam(lr=0.0001),  # You can adjust the learning rate as needed\n    loss=\"categorical_crossentropy\",\n    metrics=[\"accuracy\"]\n)","metadata":{"execution":{"iopub.status.busy":"2023-08-20T13:06:11.634650Z","iopub.execute_input":"2023-08-20T13:06:11.635003Z","iopub.status.idle":"2023-08-20T13:06:11.653046Z","shell.execute_reply.started":"2023-08-20T13:06:11.634970Z","shell.execute_reply":"2023-08-20T13:06:11.652157Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.callbacks import EarlyStopping\n\n# Define the EarlyStopping callback\nearly_stopping = EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True)\n\n# Train the model with EarlyStopping\nhistory = model.fit(\n    train_generator,\n    steps_per_epoch=len(train_generator),\n    epochs=50,\n    validation_data=valid_generator,\n    validation_steps=len(valid_generator),\n    callbacks=[early_stopping]  # Add the EarlyStopping callback\n)","metadata":{"execution":{"iopub.status.busy":"2023-08-20T13:07:25.706239Z","iopub.execute_input":"2023-08-20T13:07:25.707370Z","iopub.status.idle":"2023-08-20T13:50:29.985145Z","shell.execute_reply.started":"2023-08-20T13:07:25.707324Z","shell.execute_reply":"2023-08-20T13:50:29.983953Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visualizing Training Progress\n\nMonitoring the training progress of our machine learning model is crucial for assessing its performance and identifying potential issues like overfitting. In this section, we'll visualize the training and validation accuracy and loss using Matplotlib.\n\n## Training and Validation Accuracy Plot\n\nThe following code plots the training and validation accuracy over epochs:\n","metadata":{}},{"cell_type":"code","source":"# Plot training and validation accuracy\nplt.plot(history.history[\"accuracy\"], label=\"Training Accuracy\")\nplt.plot(history.history[\"val_accuracy\"], label=\"Validation Accuracy\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Accuracy\")\nplt.title(\"Training and Validation Accuracy\")\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-08-20T13:51:42.059247Z","iopub.execute_input":"2023-08-20T13:51:42.059737Z","iopub.status.idle":"2023-08-20T13:51:42.390062Z","shell.execute_reply.started":"2023-08-20T13:51:42.059696Z","shell.execute_reply":"2023-08-20T13:51:42.388693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot training and validation loss\nplt.plot(history.history[\"loss\"], label=\"Training Loss\")\nplt.plot(history.history[\"val_loss\"], label=\"Validation Loss\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Loss\")\nplt.title(\"Training and Validation Loss\")\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-08-20T13:51:42.393740Z","iopub.execute_input":"2023-08-20T13:51:42.395673Z","iopub.status.idle":"2023-08-20T13:51:42.876742Z","shell.execute_reply.started":"2023-08-20T13:51:42.395637Z","shell.execute_reply":"2023-08-20T13:51:42.875559Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Evaluating the Model on Test Data and Saving\n\nAfter training our tomato disease detection model, it's essential to assess its performance on unseen data to ensure its real-world utility. Additionally, saving the trained model allows us to deploy it for making predictions on new tomato leaf images.\n\n## Evaluating the Model on Test Data\n\nThe following code evaluates the trained model on the test data:\n\n","metadata":{}},{"cell_type":"code","source":"# Make predictions on test data\ntest_loss, test_accuracy = model.evaluate(valid_generator, steps=len(valid_generator))\nprint(f\"Test Loss: {test_loss:.4f}\")\nprint(f\"Test Accuracy: {test_accuracy:.4f}\")\n\n# Save the trained model\nmodel.save(\"trained_model.h5\")\nprint(\"Trained model saved as 'trained_model.h5'\")","metadata":{"execution":{"iopub.status.busy":"2023-08-20T13:51:50.966776Z","iopub.execute_input":"2023-08-20T13:51:50.967151Z","iopub.status.idle":"2023-08-20T13:51:54.150081Z","shell.execute_reply.started":"2023-08-20T13:51:50.967120Z","shell.execute_reply":"2023-08-20T13:51:54.148986Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Generating and Visualizing the Confusion Matrix\n\nThe confusion matrix is a valuable tool for assessing the performance of a classification model, especially in multi-class classification scenarios like our tomato disease detection project. In this section, we'll use the saved model to generate predictions and create a confusion matrix.\n","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nimport numpy as np\nimport seaborn as sns\n# Load the saved model\nloaded_model = tf.keras.models.load_model(\"trained_model.h5\")\n\n# Initialize variables\nnum_samples = len(valid_generator.filenames)\nbatch_size = 32\nnum_batches = int(np.ceil(num_samples / batch_size))\nall_test_labels = []\nall_predicted_labels = []\n\n# Generate predictions in batches\nfor _ in range(num_batches):\n    batch_images, batch_labels = next(valid_generator)\n    batch_predictions = loaded_model.predict(batch_images)\n    batch_predicted_labels = np.argmax(batch_predictions, axis=1)\n    \n    all_test_labels.extend(np.argmax(batch_labels, axis=1))\n    all_predicted_labels.extend(batch_predicted_labels)\n\n# Generate confusion matrix\ncm = confusion_matrix(all_test_labels, all_predicted_labels)\n\n# Plot the confusion matrix\nclass_names = [str(i) for i in range(num_classes)]  # Replace with actual class names if available\nplt.figure(figsize=(10, 8))\nsns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nplt.title('Confusion Matrix')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-08-20T13:52:56.911364Z","iopub.execute_input":"2023-08-20T13:52:56.911764Z","iopub.status.idle":"2023-08-20T13:53:03.996452Z","shell.execute_reply.started":"2023-08-20T13:52:56.911732Z","shell.execute_reply":"2023-08-20T13:53:03.995377Z"},"trusted":true},"execution_count":null,"outputs":[]}]}